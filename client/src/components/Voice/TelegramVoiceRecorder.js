/**
 * TelegramVoiceRecorder - Professional Telegram-style Voice Recording
 * Smart voice recording with waveform visualization and professional controls
 */

import React, { useState, useRef, useEffect, useCallback } from 'react';
import { 
  FiMic, 
  FiMicOff, 
  FiPlay, 
  FiPause,\n  FiSend,\n  FiTrash2,\n  FiLock,\n  FiUnlock,\n  FiVolume2\n} from 'react-icons/fi';\nimport './TelegramVoiceRecorder.css';\n\nconst TelegramVoiceRecorder = ({ \n  onVoiceMessage, \n  onCancel,\n  maxDuration = 300, // 5 minutes\n  className = ''\n}) => {\n  const [isRecording, setIsRecording] = useState(false);\n  const [isPaused, setIsPaused] = useState(false);\n  const [isPlaying, setIsPlaying] = useState(false);\n  const [duration, setDuration] = useState(0);\n  const [audioBlob, setAudioBlob] = useState(null);\n  const [audioUrl, setAudioUrl] = useState(null);\n  const [waveformData, setWaveformData] = useState([]);\n  const [isLocked, setIsLocked] = useState(false);\n  const [volume, setVolume] = useState(0);\n  const [recordingState, setRecordingState] = useState('idle'); // 'idle', 'recording', 'recorded', 'playing'\n  \n  const mediaRecorderRef = useRef(null);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n  const audioChunksRef = useRef([]);\n  const streamRef = useRef(null);\n  const intervalRef = useRef(null);\n  const audioRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  // Initialize audio context and analyzer\n  const initializeAudio = useCallback(async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ \n        audio: {\n          echoCancellation: true,\n          noiseSuppression: true,\n          autoGainControl: true,\n          sampleRate: 44100\n        } \n      });\n      \n      streamRef.current = stream;\n      \n      // Create audio context for waveform visualization\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      \n      const source = audioContextRef.current.createMediaStreamSource(stream);\n      source.connect(analyserRef.current);\n      \n      analyserRef.current.fftSize = 256;\n      \n      // Create media recorder\n      mediaRecorderRef.current = new MediaRecorder(stream, {\n        mimeType: 'audio/webm;codecs=opus'\n      });\n      \n      mediaRecorderRef.current.ondataavailable = (event) => {\n        if (event.data.size > 0) {\n          audioChunksRef.current.push(event.data);\n        }\n      };\n      \n      mediaRecorderRef.current.onstop = () => {\n        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });\n        const audioUrl = URL.createObjectURL(audioBlob);\n        \n        setAudioBlob(audioBlob);\n        setAudioUrl(audioUrl);\n        setRecordingState('recorded');\n        \n        // Clean up\n        if (streamRef.current) {\n          streamRef.current.getTracks().forEach(track => track.stop());\n        }\n      };\n      \n      return true;\n    } catch (error) {\n      console.error('Failed to initialize audio:', error);\n      return false;\n    }\n  }, []);\n\n  // Start recording\n  const startRecording = useCallback(async () => {\n    const initialized = await initializeAudio();\n    if (!initialized) return;\n    \n    audioChunksRef.current = [];\n    setDuration(0);\n    setWaveformData([]);\n    setIsRecording(true);\n    setRecordingState('recording');\n    \n    mediaRecorderRef.current.start(100); // Collect data every 100ms\n    \n    // Start duration timer\n    intervalRef.current = setInterval(() => {\n      setDuration(prev => {\n        const newDuration = prev + 0.1;\n        if (newDuration >= maxDuration) {\n          stopRecording();\n          return maxDuration;\n        }\n        return newDuration;\n      });\n    }, 100);\n    \n    // Start waveform visualization\n    visualizeWaveform();\n  }, [maxDuration]);\n\n  // Stop recording\n  const stopRecording = useCallback(() => {\n    if (mediaRecorderRef.current && isRecording) {\n      mediaRecorderRef.current.stop();\n      setIsRecording(false);\n      \n      if (intervalRef.current) {\n        clearInterval(intervalRef.current);\n      }\n    }\n  }, [isRecording]);\n\n  // Pause/Resume recording\n  const togglePauseRecording = useCallback(() => {\n    if (!mediaRecorderRef.current) return;\n    \n    if (isPaused) {\n      mediaRecorderRef.current.resume();\n      setIsPaused(false);\n      \n      // Resume timer\n      intervalRef.current = setInterval(() => {\n        setDuration(prev => {\n          const newDuration = prev + 0.1;\n          if (newDuration >= maxDuration) {\n            stopRecording();\n            return maxDuration;\n          }\n          return newDuration;\n        });\n      }, 100);\n    } else {\n      mediaRecorderRef.current.pause();\n      setIsPaused(true);\n      \n      if (intervalRef.current) {\n        clearInterval(intervalRef.current);\n      }\n    }\n  }, [isPaused, maxDuration, stopRecording]);\n\n  // Visualize waveform\n  const visualizeWaveform = useCallback(() => {\n    if (!analyserRef.current) return;\n    \n    const bufferLength = analyserRef.current.frequencyBinCount;\n    const dataArray = new Uint8Array(bufferLength);\n    \n    const updateWaveform = () => {\n      if (!isRecording) return;\n      \n      analyserRef.current.getByteFrequencyData(dataArray);\n      \n      // Calculate average volume\n      const average = dataArray.reduce((sum, value) => sum + value, 0) / bufferLength;\n      const normalizedVolume = average / 255;\n      \n      setVolume(normalizedVolume);\n      \n      // Add to waveform data (keep last 100 samples)\n      setWaveformData(prev => {\n        const newData = [...prev, normalizedVolume];\n        return newData.slice(-100);\n      });\n      \n      requestAnimationFrame(updateWaveform);\n    };\n    \n    updateWaveform();\n  }, [isRecording]);\n\n  // Play recorded audio\n  const playRecording = useCallback(() => {\n    if (!audioUrl || !audioRef.current) return;\n    \n    if (isPlaying) {\n      audioRef.current.pause();\n      setIsPlaying(false);\n    } else {\n      audioRef.current.play();\n      setIsPlaying(true);\n    }\n  }, [audioUrl, isPlaying]);\n\n  // Send voice message\n  const sendVoiceMessage = useCallback(() => {\n    if (!audioBlob) return;\n    \n    const voiceMessage = {\n      blob: audioBlob,\n      url: audioUrl,\n      duration: duration,\n      waveform: waveformData,\n      timestamp: Date.now(),\n      size: audioBlob.size\n    };\n    \n    onVoiceMessage(voiceMessage);\n    resetRecorder();\n  }, [audioBlob, audioUrl, duration, waveformData, onVoiceMessage]);\n\n  // Cancel recording\n  const cancelRecording = useCallback(() => {\n    if (isRecording) {\n      stopRecording();\n    }\n    resetRecorder();\n    onCancel?.();\n  }, [isRecording, stopRecording, onCancel]);\n\n  // Reset recorder state\n  const resetRecorder = useCallback(() => {\n    setIsRecording(false);\n    setIsPaused(false);\n    setIsPlaying(false);\n    setDuration(0);\n    setAudioBlob(null);\n    setAudioUrl(null);\n    setWaveformData([]);\n    setIsLocked(false);\n    setVolume(0);\n    setRecordingState('idle');\n    \n    if (intervalRef.current) {\n      clearInterval(intervalRef.current);\n    }\n    \n    if (streamRef.current) {\n      streamRef.current.getTracks().forEach(track => track.stop());\n    }\n    \n    audioChunksRef.current = [];\n  }, []);\n\n  // Handle audio playback events\n  useEffect(() => {\n    if (audioRef.current) {\n      const audio = audioRef.current;\n      \n      const handleEnded = () => setIsPlaying(false);\n      const handlePause = () => setIsPlaying(false);\n      \n      audio.addEventListener('ended', handleEnded);\n      audio.addEventListener('pause', handlePause);\n      \n      return () => {\n        audio.removeEventListener('ended', handleEnded);\n        audio.removeEventListener('pause', handlePause);\n      };\n    }\n  }, [audioUrl]);\n\n  // Cleanup on unmount\n  useEffect(() => {\n    return () => {\n      resetRecorder();\n      if (audioContextRef.current) {\n        audioContextRef.current.close();\n      }\n    };\n  }, [resetRecorder]);\n\n  // Format duration\n  const formatDuration = (seconds) => {\n    const mins = Math.floor(seconds / 60);\n    const secs = Math.floor(seconds % 60);\n    return `${mins}:${secs.toString().padStart(2, '0')}`;\n  };\n\n  // Render waveform\n  const renderWaveform = () => {\n    if (waveformData.length === 0) return null;\n    \n    return (\n      <div className=\"waveform-container\">\n        {waveformData.map((amplitude, index) => (\n          <div\n            key={index}\n            className=\"waveform-bar\"\n            style={{\n              height: `${Math.max(amplitude * 100, 2)}%`,\n              opacity: isRecording ? 1 : 0.6\n            }}\n          />\n        ))}\n      </div>\n    );\n  };\n\n  return (\n    <div className={`telegram-voice-recorder ${recordingState} ${className}`}>\n      {/* Hidden audio element for playback */}\n      {audioUrl && (\n        <audio ref={audioRef} src={audioUrl} preload=\"metadata\" />\n      )}\n      \n      {recordingState === 'idle' && (\n        <div className=\"recorder-idle\">\n          <button \n            className=\"record-btn\"\n            onMouseDown={startRecording}\n            onTouchStart={startRecording}\n          >\n            <FiMic className=\"mic-icon\" />\n            <span>Hold to Record</span>\n          </button>\n        </div>\n      )}\n      \n      {recordingState === 'recording' && (\n        <div className=\"recorder-active\">\n          <div className=\"recording-controls\">\n            <button className=\"control-btn\" onClick={togglePauseRecording}>\n              {isPaused ? <FiPlay /> : <FiPause />}\n            </button>\n            \n            <button \n              className={`lock-btn ${isLocked ? 'locked' : ''}`}\n              onClick={() => setIsLocked(!isLocked)}\n            >\n              {isLocked ? <FiLock /> : <FiUnlock />}\n            </button>\n          </div>\n          \n          <div className=\"recording-info\">\n            <div className=\"duration-display\">\n              <div className=\"recording-indicator\" />\n              <span>{formatDuration(duration)}</span>\n            </div>\n            \n            <div className=\"volume-indicator\">\n              <FiVolume2 />\n              <div className=\"volume-bar\">\n                <div \n                  className=\"volume-fill\" \n                  style={{ width: `${volume * 100}%` }}\n                />\n              </div>\n            </div>\n          </div>\n          \n          {renderWaveform()}\n          \n          <div className=\"recording-actions\">\n            <button className=\"cancel-btn\" onClick={cancelRecording}>\n              <FiTrash2 />\n            </button>\n            \n            <button className=\"stop-btn\" onClick={stopRecording}>\n              <FiMicOff />\n            </button>\n          </div>\n        </div>\n      )}\n      \n      {recordingState === 'recorded' && (\n        <div className=\"recorder-playback\">\n          <div className=\"playback-controls\">\n            <button className=\"play-btn\" onClick={playRecording}>\n              {isPlaying ? <FiPause /> : <FiPlay />}\n            </button>\n            \n            <div className=\"playback-info\">\n              <span className=\"duration\">{formatDuration(duration)}</span>\n              <div className=\"waveform-preview\">\n                {waveformData.slice(-20).map((amplitude, index) => (\n                  <div\n                    key={index}\n                    className=\"mini-bar\"\n                    style={{ height: `${Math.max(amplitude * 100, 10)}%` }}\n                  />\n                ))}\n              </div>\n            </div>\n          </div>\n          \n          <div className=\"playback-actions\">\n            <button className=\"delete-btn\" onClick={cancelRecording}>\n              <FiTrash2 />\n            </button>\n            \n            <button className=\"send-btn\" onClick={sendVoiceMessage}>\n              <FiSend />\n            </button>\n          </div>\n        </div>\n      )}\n    </div>\n  );\n};\n\nexport default TelegramVoiceRecorder;"